{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **RNN MODEL**"
      ],
      "metadata": {
        "id": "SyEVdDw4_Yfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing Libraries"
      ],
      "metadata": {
        "id": "_Z3CgptM_iC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras import preprocessing"
      ],
      "metadata": {
        "id": "sryiZXT2_oDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset loading"
      ],
      "metadata": {
        "id": "EUyZNcVV_pY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DOUJfsh_Fdn",
        "outputId": "32bc59eb-0999-415f-d570-cd29a961ea48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Shape of training data: (25000, 200)\n",
            "Shape of test data: (25000, 200)\n"
          ]
        }
      ],
      "source": [
        "# Set parameters for the data.\n",
        "# max_features: The number of words to consider as features (e.g., the top 10,000 most frequent words).\n",
        "max_features = 10000\n",
        "\n",
        "# maxlen: The maximum length of each movie review. Longer reviews will be truncated, shorter ones will be padded.\n",
        "maxlen = 200\n",
        "\n",
        "# Load the IMDB dataset. The words are already encoded as integers.\n",
        "# 'num_words=max_features' keeps only the top 'max_features' words.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess the data to ensure all sequences have the same length.\n",
        "# 'padding=\"post\"' adds zeros at the end of reviews that are shorter than 'maxlen'.\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen, padding=\"post\")\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen, padding=\"post\")\n",
        "\n",
        "print(\"Shape of training data:\", x_train.shape)\n",
        "print(\"Shape of test data:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the RNN Model"
      ],
      "metadata": {
        "id": "tfRQ79Pu__CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rnn_model():\n",
        "    # Use the Sequential API to build a model layer by layer.\n",
        "    model = Sequential()\n",
        "\n",
        "    # The Embedding layer: This takes the integer-encoded words and maps them to dense vectors.\n",
        "    # It learns a numerical representation for each word.\n",
        "    # Arguments: (number of words, embedding dimension, input length).\n",
        "    model.add(Embedding(max_features, 32))\n",
        "\n",
        "    # The SimpleRNN layer: This is the core of the RNN.\n",
        "    # It processes the sequences of word vectors one at a time, maintaining an internal state.\n",
        "    # The '32' is the number of units in the RNN layer.\n",
        "    model.add(SimpleRNN(32))\n",
        "\n",
        "    # The final output layer: A single neuron with a 'sigmoid' activation function.\n",
        "    # The sigmoid function squashes the output to a value between 0 and 1,\n",
        "    # representing the probability that the review is positive.\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ffK8wxm7_7o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and Train the Model"
      ],
      "metadata": {
        "id": "oZLfE_jtAFBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model.\n",
        "rnn_model = create_rnn_model()\n",
        "\n",
        "# Compile the model with an optimizer, a loss function, and metrics to monitor.\n",
        "# 'rmsprop' is a good optimizer for RNNs.\n",
        "# 'binary_crossentropy' is the standard loss function for binary classification (positive or negative).\n",
        "# 'accuracy' is the metric we'll use to measure how well the model performs.\n",
        "rnn_model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data.\n",
        "# 'epochs' is the number of times the model will see the entire dataset.\n",
        "# 'batch_size' is the number of samples per gradient update.\n",
        "history = rnn_model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V-LgXWJADlu",
        "outputId": "20aebbb2-1f2f-49f4-fdcd-66e838f14b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.5079 - loss: 0.6925 - val_accuracy: 0.5430 - val_loss: 0.6844\n",
            "Epoch 2/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.5857 - loss: 0.6646 - val_accuracy: 0.5500 - val_loss: 0.6871\n",
            "Epoch 3/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 66ms/step - accuracy: 0.6665 - loss: 0.6059 - val_accuracy: 0.6608 - val_loss: 0.6404\n",
            "Epoch 4/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - accuracy: 0.6978 - loss: 0.5529 - val_accuracy: 0.6812 - val_loss: 0.6298\n",
            "Epoch 5/5\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7974 - loss: 0.4543 - val_accuracy: 0.6424 - val_loss: 0.6571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model"
      ],
      "metadata": {
        "id": "_k0sXhk7AQ_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset.\n",
        "# This gives us a final measure of how well the model generalizes to new data.\n",
        "loss, accuracy = rnn_model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"\\nTest loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N_gz8WPAMmM",
        "outputId": "0fbc76ca-4896-4ff3-aa67-1b2f6c9cc8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6371 - loss: 0.6663\n",
            "\n",
            "Test loss: 0.6677\n",
            "Test accuracy: 0.6345\n"
          ]
        }
      ]
    }
  ]
}